---
output: word_document
---
```{r}
#library(lubridate)
#library(lazyeval)
install.packages('plotly', repos = 'http://cran.us.r-project.org')
library(ggplot2)
library(GGally)
```


```{r echo=TRUE}
checkNaFunction <- function(houseData){
naColumns <- c()
#checking NA for each columns
for(i in 1:ncol(houseData)) {
  #cat(sprintf("Checking NA: %s \n", colnames(houseData)[i]))
  if(length(which(is.na(houseData[,i]))) > 0){
    #cat(sprintf("There is NA: %s \n" , colnames(houseData)[i]))
    naColumns <- c(naColumns, colnames(houseData)[i])
  }
}
return(naColumns)
}

```


```{r echo=TRUE}
bucketByColumn <- function(houseData,i){
minP <- min(as.numeric(houseData[,i]))
maxP <- max(as.numeric(houseData[,i]))
rangeP <- range(as.numeric(houseData[,i]))
rangeP
cat(sprintf("Min-Max value for: %s , MAX: %d, MIN: %d \n", colnames(houseData)[i], minP, maxP))
}

```



```{r echo=TRUE}
analysis <- function(houseData, i, labels, plotLog){
  plot(houseData$price~houseData[,i],main = labels[1],xlab = labels[2],ylab = labels[3], col=(c("gold","darkgreen")))
  
  plot(houseData[,i],log(houseData$price), main=cat(labels[1]), xlab=cat(labels[2]), ylab=cat("Log of ",labels[3]), col=(c("gold","darkgreen")))
  
  if(plotLog=='Y'){
    plot(log(houseData[,i]),log(houseData$price), main=cat("Log ",labels[1]), xlab=cat("Log of ",labels[2]), ylab=cat("Log of ",labels[3]), col=(c("gold","darkgreen")))
  }
  
  hist(houseData[,i],main = labels[1],xlab = labels[2],ylab = labels[3],col=(c("gold","darkgreen")))

  boxplot(houseData[,i],main = labels[1],col=(c("gold","darkgreen")))
  
  cor(houseData[,i],houseData$price)
}

```


#Data Importing And Cleaning
```{r echo=TRUE}
houseData <- read.csv("file:///G:/Ryerson-BigData/capstone-R/CKME-136/data/kc_house_data.csv")
head(houseData)
colnames(houseData)
naColumns <- checkNaFunction(houseData)
if(length(naColumns)>0){
  cat("Found NA Colums:")
  for(i in 1:length(naColumns)) {
    cat(sprintf("%s,", colnames(houseData)[i]))
  }
}

#houseData$date<-(substr(houseData$date, 1, 8))
#houseData$date<- ymd(houseData$date)
#houseData$date<-as.numeric(as.Date(houseData$date, origin = "1900-01-01"))

# Here we conclude that this data does not hold any column with NA.
bucketByColumn(houseData,3)

```

#Price with other attributes
```{r echo=TRUE}
## verify the relationship between price, bedrooms, bathrooms, sqft_living and sqft lot
plot1 <- ggpairs(data=houseData, columns=3:7, mapping = aes(color = "dark green"),              axisLabels="show")
plot1

## verify the relationship between price, floors, waterfront, view, condition and grade
plot2 <- ggpairs(data=houseData, columns=c(3,8:12),
               mapping = aes(color = "dark green"),
               axisLabels="show")
plot2

## verify the relationship between price, yr built, lat and long
plot3 <- ggpairs(data=houseData, columns=c(3,15,18,19),
              mapping = aes(color = "dark green"),
              axisLabels="show")
plot3

```


##Correlation among all the variables
```{r echo=TRUE}
#Only sqft_living & sqft_above,sqft_living & grade,sqft_living & bathrooms have good correlation between them
#Remove the columns which does not hold any significance in predicing house price
houseData$date <- NULL
houseData$id <- NULL
cor(houseData)
# we can see that zip-code has very weak co-orelation -0.053202854, so let us remove it
houseData$zipcode <- NULL
houseData <- read.csv("file:///G:/Ryerson-BigData/capstone-R/CKME-136/data/kc_house_data.csv")

```

#Now Let us do analysis of price with all other variables
#Bedroom  Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,4)
analysis(houseData,4,c('Bedrooms vs. price','Bedrooms', 'Price of House'), 'Y')
#*******Removing the outliers
#Since more than 7 bedrooms are very rare.Also it's the outlier for my model.
#I  have removed  the outlier data.
houseData<-subset(houseData,bedrooms>=1 & bedrooms<=7)
#*******Once we removed the outliers, again get the analysis
analysis(houseData,4,c('Bedrooms vs. price','Bedrooms', 'Price of House'), 'Y')
bucketByColumn(houseData,4)
## here we found that log of bedroom give better performance.
```


#Bathroom Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,5)
analysis(houseData,5,c('Bathrooms vs. price','Bathrooms', 'Price of House'), 'Y')
## Price vs. Bathrooms, here we can find good correlation, as number of bahtrooms increases, price increases as well, with one expection in when bathroom=7
#*******Removing the outliers
#More than 4 bathrooms are very rare in this data.So I am removing it.
houseData<-subset(houseData,bathrooms>=1 & bathrooms<=4)
analysis(houseData,5,c('Bathrooms vs. price','Bathrooms', 'Price of House'), 'Y')
bucketByColumn(houseData,5)
## here we found that log of bathrooms give better performance.
```


#SQFT Living  Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,6)
analysis(houseData,6,c('Living-Sqft vs. price','Living-Sqft', 'Price of House'), 'Y')
## Price vs. Sqft_living ->> Nice correlation, as sqft increases, price increases as well.
#*******Removing the outliers
houseData<-subset(houseData,sqft_living >1000 & sqft_living<=4000)
analysis(houseData,6,c('Living-Sqft vs. price','Living-Sqft', 'Price of House'), 'Y')
bucketByColumn(houseData,6)

## Price vs. Sqft_living ->> Nice correlation, as sqft increases, price increases as well.

```


## SQFT_LOT Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,7)
analysis(houseData,7,c('LotSize vs. price','LotSize', 'Price of House'), 'Y')
#*******Removing the outliers
houseData<-subset(houseData,sqft_lot>=0 & sqft_lot<=25000)
analysis(houseData,7,c('LotSize vs. price','LotSize', 'Price of House'), 'Y')
bucketByColumn(houseData,7)
```

## FLOOR Vs Price analysis
```{r echo=TRUE}
analysis(houseData,8,c('Floors vs. price','Floor', 'Price of House'), 'Y')
#bucketByColumn(houseData,8)
```

## SQFT_LOT Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,9)
analysis(houseData,9,c('WaterFront vs. price','WaterFront', 'Price of House'), 'Y')
#*******Removing the outliers
houseData<-subset(houseData,sqft_lot>=0 & sqft_lot<=25000)
analysis(houseData,9,c('WaterFront vs. price','WaterFront', 'Price of House'), 'Y')
bucketByColumn(houseData,9)
```


## View Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,10)
analysis(houseData,10,c('View vs. price','View', 'Price of House'), 'Y')
## Price vs. View ->> Nice correlation, view increases [median of bar plot], price increases as well
#*******Removing the outliers
analysis(houseData,10,c('View vs. price','View', 'Price of House'), 'Y')
bucketByColumn(houseData,10)
```


##CONDITION Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,11)
analysis(houseData,11,c('Condition vs. price','condition', 'Price of House'), 'Y')
#*******Removing the outliers
houseData<-subset(houseData,condition>=3& condition<=5)
analysis(houseData,11,c('Condition vs. price','condition', 'Price of House'), 'Y')
bucketByColumn(houseData,11)
```


##Grade Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,12)
analysis(houseData,12,c('Grade vs. price','Grade', 'Price of House'), 'Y')
## Price vs. Grade ->> Nice correlation, grade increases [median of bar plot], price increases as well
#*******Removing the outliers
#Most of the houses grades are between 6-10 
houseData<-subset(houseData,grade >= 6 & grade<=10)
analysis(houseData,12,c('Grade vs. price','Grade', 'Price of House'), 'Y')
bucketByColumn(houseData,12)
#grade is good without log 
```

#SQFT_ABOVE Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,13)
analysis(houseData,13,c('MainHouseSize vs. price','MainHouseSize', 'Price of House'), 'Y')
#*******Removing the outliers
houseData<-subset(houseData,sqft_above >=500 & sqft_above<=3500)
analysis(houseData,13,c('MainHouseSize vs. price','MainHouseSize', 'Price of House'), 'Y')
bucketByColumn(houseData,13)

```


##SQFT_BASEMENT Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,14)
analysis(houseData,14,c('BasementSize vs. price','BasementSize', 'Price of House'), 'Y')
#*******Removing the outliers
houseData<-subset(houseData,sqft_basement >=0 & sqft_basement<=1500)
analysis(houseData,14,c('BasementSize vs. price','BasementSize', 'Price of House'), 'Y')
bucketByColumn(houseData,14)
```


#YR_BUILT Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,15)
analysis(houseData,15,c('YearBuilt vs. price','YearBuilt', 'Price of House'), 'Y')
#*******Removing the outliers
#In our data some records are too old..I just removed that data from my model.
#Because It doesn't make any sense to keep more than 100 years house in our model
houseData<-subset(houseData,yr_built>=1950& yr_built<=2015)
analysis(houseData,15,c('YearBuilt vs. price','YearBuilt', 'Price of House'), 'Y')
bucketByColumn(houseData,15)
```

#YR_BUILT Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,16)
analysis(houseData,16,c('YearRenovated vs. price','YearRenovated', 'Price of House'), 'Y')
#*******Removing the outliers
#In our data some records are too old..I just removed that data from my model.
#Because It doesn't make any sense to keep more than 100 years house in our model
houseData<-subset(houseData,yr_renovated>=1950& yr_renovated<=2015)
analysis(houseData,16,c('YearRenovated vs. price','YearRenovated', 'Price of House'), 'Y')
bucketByColumn(houseData,16)
```


#ZIPCODE Vs Price analysis
```{r echo=TRUE}
analysis(houseData,17,c('ZipCode vs. price','ZipCode', 'Price of House'), 'Y')
```



##LAT Vs Price analysis
```{r echo=TRUE}

analysis(houseData,18,c('Latitude vs. price','latitude', 'Price of House'), 'N')
## Price vs. Lat ->> This is more like a normal dist relationship, price peaks around when lat= 47.64 and declines afterwards, but this can be modeled easily. I would say Lat explains the price as well.
#*******Removing the outliers
houseData<-subset(houseData,lat>=47.3)
analysis(houseData,18,c('Latitude vs. price','latitude', 'Price of House'), 'N')
```

## LONG Vs Price analysis
```{r echo=TRUE}
analysis(houseData,19,c('Longitude vs. price','Longitude', 'Price of House'), 'N')
#*******Removing the outliers
houseData<-subset(houseData,long>=-122.4 & long < -121.8)
analysis(houseData,19,c('Longitude vs. price','Longitude', 'Price of House'), 'N')
```



## SQFT_LIVING15 Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,20)
analysis(houseData,20,c('sqft_living15 vs. price','sqft_living15', 'Price of House'), 'Y')

```

##SQFT_LOT15 Vs Price analysis
```{r echo=TRUE}
bucketByColumn(houseData,21)
analysis(houseData,21,c('sqft_lot15 vs. price','sqft_lot15', 'Price of House'), 'Y')
#*******Removing the outliers
houseData<-subset(houseData,sqft_lot15>=0 & sqft_lot<=20000)
analysis(houseData,21,c('sqft_lot15 vs. price','sqft_lot15', 'Price of House'), 'Y')
bucketByColumn(houseData,21)

```


## My fisrt 5 variables are: sqft_living, bathrooms, grade, view and lat.
## Each of box plots shows that above variables might be directly related in predicting house prices.

## To support my finding, I also computed correlation between prices and variables, and my top 5 picks are supported with correlation coefficients as well [see below]

## Plots 1,2 and 3 shows the correlation between each variables and they are:
# corr between price vs sqft_living: 0.70203505
# corr between price vs bathrooms: 0.52513751
# corr between price vs bedrooms: 0.308349598
# corr between price vs sqft_lot: 0.089660861
# corr between price vs floors: 0.256793888
# corr between price vs waterfront: 0.266369434
# corr between price vs view: 0.397293488
# corr between price vs condition: 0.036361789
# corr between price vs grade: 0.66743426
# corr between price vs sqft_above: 0.6055672984
# corr between price vs yr_built: 0.05401153
# corr between price vs lat: 0.3070034800
# corr between price vs long: 0.02162624

##Start with price & sqft_living
```{r echo=TRUE}
analysis(houseData,6,c('Living-Sqft vs. price','Living-Sqft', 'Price of House'), 'Y')

## Since this scatterplot is too crowded - I will plot aggregated vectors to see the relationship between 2 variables. 
vec_price_sqftliving <-aggregate(price~sqft_living, FUN=mean, data=houseData)
plot(vec_price_sqftliving, col=(c("gold","darkgreen")))
scatterplot1<-recordPlot()

## Plot does not show that price and sqft_living are linearly related. It looks like an exponential relationship.

## I am using aggregated data as opposed to using the raw data. By "aggragated" data, I mean I take the mean for all the same sqft_living.

plot(log(vec_price_sqftliving$sqft_living),log(vec_price_sqftliving$price), main="Log of Sqft_Living vs. Log of Price of House", xlab="Log Sqft_Living", ylab="Log Price of House", col=(c("gold","darkgreen")))
scatterplot2<-recordPlot()


```


## Selection Method: START
## We have suggested 12 variables. I will calculate SSE and see which one gives me a smaller SSE and I pick that variable.

## From above correlation, variables selected are:  bedrooms, bathrooms, log(sqft living), log(sqft lot), floors, waterfront, view, condition, grade, yr built, lat, long

```{r echo=TRUE}
## Start with one variable predication
## Creating Models using 1 variables fpr each of the variables with price, so total we have 12 Models. 
rn_train <- sample(nrow(houseData),floor(nrow(houseData)*0.60))
train <- houseData[rn_train,colnames(houseData)]
test <- houseData[-rn_train,colnames(houseData)]

SSEVals <- list(c(), c())
findSSEByIndesx <- function(i){
modlm<-lm(as.formula(paste("log(price)~", paste(c(colnames(houseData)[i]), collapse="+"))),data=train)
  predt<-exp(predict(modlm,newdata=test))
  SSE<-sum((test$price-predt)^2)
  SSEVals[1]<-c(SSEVals[1],i)
  SSEVals[2]<-c(SSEVals[2],SSE)
}

findSSEByColName <- function(colName, SSEVals){
  modlm<-lm(as.formula(paste("log(price)~", paste(c(colName), collapse="+"))),data=train)
  ## Predicting prices using each Model. we need to take exponent of predict function since it returns log of price.
  predt<-exp(predict(modlm,newdata=test))
  SSE<-sum((test$price-predt)^2)
  SSEVals[[1]]<-c(SSEVals[[1]],colName)
  SSEVals[[2]]<-c(SSEVals[[2]],SSE)
  return(SSEVals)
}

SSEVals = findSSEByColName('bedrooms', SSEVals)
SSEVals = findSSEByColName('bathrooms', SSEVals)
SSEVals = findSSEByColName('log(sqft_living)', SSEVals)
SSEVals = findSSEByColName('log(sqft_lot)', SSEVals)
SSEVals = findSSEByColName('floors', SSEVals)
SSEVals = findSSEByColName('waterfront', SSEVals)
SSEVals = findSSEByColName('view', SSEVals)
SSEVals = findSSEByColName('condition', SSEVals)
SSEVals = findSSEByColName('grade', SSEVals)
SSEVals = findSSEByColName('yr_built', SSEVals)
SSEVals = findSSEByColName('lat', SSEVals)
SSEVals = findSSEByColName('long', SSEVals)
SSEArr = SSEVals[[2]];
which(SSEArr==min(SSEArr))
SSEVals[[1]][which(SSEArr==min(SSEArr))]

## Conculsion: SSE is minimum for variable grade so it is the best predictor, when we use single variable.

```


```{r echo=TRUE}
# As in last phase, grade is bet to predict the price with single variable, let us name is model01 & compute r_square for the model
#R-squared is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression. 0% indicates that the model explains none of the variability of the response data around its mean

model01 <- lm(data=train,log(price)~grade)
r_squared_model01<-summary(model01)$r.squared


# Now let us add more variable which has greater impact on the price prediction. Let us call it model02. here i have selecetd log(sqft_living), bedrooms, bathrooms, grade, waterfront

model02<-lm(log(price)~log(sqft_living)+bedrooms+bathrooms+grade+waterfront,data=train)
summary(model02)

r_squared_model02<-summary(model02)$r.squared

cat("\nR-Squared for Model-02 is ",100*(r_squared_model02/r_squared_model01-1),"% better than Model-01.\nR-squared for Model-02 and Model-01  are:", r_squared_model02, "and", r_squared_model01, "respectively.")

##compute RMSE for Model-02
predic_model02<-exp(predict(model02,newdata=test)) 
RMSE_model02=sqrt(sum((predic_model02 - test$price)^2)/nrow(test)) 

```
## If we plot residual vs. a variable that is not used in the prediction and if we see any recognizable patterns, thenit indicates that some of the variation in residual is due to non-used variable therefore we should include it in our model to reduce the residual errors. 
## To calculate residuals, we simply need to substract predic_model02 from the actual price.
```{r echo=TRUE}
# here we are trying to find more eligible cariable which can impact prediction of price

residual_model02=test$price - predic_model02
## Residual vs. sqft_lot
plot(test$sqft_lot,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. floors
plot(test$floors,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. view
plot(test$view,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. condition
plot(test$condition,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. sqft_above
plot(test$sqft_above,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. sqft_basement
plot(test$sqft_basement,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. yr_built
plot(test$yr_built,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. yr_renovated
plot(test$yr_renovated,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. zipcode
plot(test$zipcode,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. lat
plot(test$lat,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. long
plot(test$long,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. sqft_living15
plot(test$sqft_living15,residual_model02, col=(c("gold","darkgreen"))) 
## Residual vs. sqft_lot15
plot(test$sqft_lot15,residual_model02, col=(c("gold","darkgreen"))) 

cat("\nConclusion: After analzing scattered plot, we found that yr_built & lat are good candidate to predict the price of house")

```

```{r echo=TRUE}
#Now create model03, which will include yr_built & lat and we will try to find model03 vs model02
model03<-lm(log(price)~log(sqft_living)+bedrooms+bathrooms+grade+waterfront+yr_built+lat,data=train)
summary(model03)

r_squared_model03<-summary(model03)$r.squared

cat("\nR-Squared for Model-03 is ",100*(r_squared_model03/r_squared_model02-1),"% better than Model-02.\nR-squared for Model-03 and Model-02 are:", r_squared_model03,"and", r_squared_model02, "respectively.So here Model-03 wins over other previous model.")

## RMSE for Model-03:
predic_model03<-exp(predict(model03,newdata=test))
RMSE_model03=sqrt(sum((predic_model03 - test$price)^2)/nrow(test))

cat("\nRMSE for model02:",RMSE_model02,"\nRMSE for model03:",RMSE_model03)

cat("\nConclusion: RMSE for Model-02 is ",round(100*(RMSE_model02/RMSE_model03-1),2),"% more than Model-03. So Model-03 predicts the prices better.")

```

```{r echo=TRUE}
#log(price) seems to have good correlation with exp(bathrooms)
#log(price) seems to have good correlation with log(lat). to reduce the noice and we will use lat-min(lat), so that relative relation can be found. Similar approach has been taken for long
#log(price) seems to have good correlation with log(yr_renovated). to get more relevent data we wil try to compute the age of the building
#bedroom & bathroom can also play a big role when price of an house is being calculate, so i have use bedrooms*bathrooms as one of the variable to compute linear model
#grade & condition can also play a big role when price of an house is being calculate, so i have use log(grade)*exp(condition) as one of the variable to compute linear model

modelComplex<-lm(log(price)~log(sqft_living)+log(bedrooms+0.5)+exp(bathrooms)+grade+waterfront+log(abs(lat-min(lat))+0.5)+log(abs(long-min(long))+0.05)+log(view+0.5)+condition+log(sqft_above+0.05)+log(sqft_basement+0.05)+log(sqft_lot15)+log(2015-yr_renovated+1)+(bedrooms*bathrooms)+(log(grade)*exp(condition))+(bedrooms*log(sqft_living))+(view*bedrooms),data=train)

summary(modelComplex)

## computing RMSE for Model-Complex
predic_modelComplex<-round(exp(predict(modelComplex,newdata=test)),0) 
RMSE_modelComplex=sqrt(sum((predic_modelComplex - test$price)^2)/nrow(test))  

cat("RMSE for model03:",RMSE_model03,"\nRMSE for modelComplex:",RMSE_modelComplex)

cat("Conclusion: RMSE for Model-03 is ",round(100*(RMSE_model03/RMSE_modelComplex-1),2),"% more than Model-Complex, so here Model-Complex is the clear winner.")

```
## Selection Method: End

#houseData regression Model
#once above model become winner, let us run the model on different set of test and training data and find the best Model Equestion.
# I took 60% for the training and 40 % for the testing dataset.
```{r echo=TRUE}
set.seed(1)
newhouseData <- subset(houseData, select  = c(price,bathrooms,sqft_living,grade,sqft_above, bedrooms, waterfront, lat, long, view, condition, sqft_basement, yr_renovated, sqft_lot15))
i=0.6
storage <- list(c(), c(), c(),c())
for(i in seq(from=0.60, to=0.95, by=0.02)){
  rn_train <- sample(nrow(newhouseData),floor(nrow(newhouseData)*i))
  train <- newhouseData[rn_train,colnames(newhouseData)]
  test <- newhouseData[-rn_train,colnames(newhouseData)]
  model <- lm(log(price)~log(sqft_living)+log(bedrooms+0.5)+exp(bathrooms)+grade+waterfront+log(abs(lat-min(lat))+0.2)+log(abs(long-min(long))+0.01)+log(view+0.5)+condition+log(sqft_above+0.05)+log(sqft_basement+0.001)+log(sqft_lot15)+log(2015-yr_renovated+1)+(bedrooms*bathrooms)+(log(grade)*exp(condition))+(bedrooms*log(sqft_living))+(view*bedrooms),data=train)
  
  prediction <- round(exp(predict(model,newdata = test)),0)
  train_prediction = fitted(model)
  training_rmse = sqrt(sum((train_prediction-train$price)^2)/nrow(train))
  testing_rmse = sqrt(sum((prediction - test$price)^2)/nrow(test))
  cat("\r\n", i)
  print(model)
  storage[[1]]<-c(storage[[1]],prediction)
  storage[[2]]<-c(storage[[2]],testing_rmse)
  storage[[3]]<-c(storage[[3]],test)
  storage[[4]]<-c(storage[[4]],training_rmse)
}

##find the LM with minimun training error
indx = which(storage[[2]]==min(storage[[2]]))
indx
cat("\nRMSE of training model after regression:",storage[[4]][indx],"\nRMSE of testing model after regression:",storage[[2]][indx])
finalPredict = storage[[1]][indx]
testData = storage[[3]][indx]

```

```{r echo=TRUE}
#Now write the Real & Predicted price file for comparision
output <- (cbind("ID"=testData$id,"Orginal Price"=testData$price,"Predicted Price"=RMSE_modelComplex))
write.csv(output, file = "RealPriceVsPredictedAsStaticticalAnalysis.csv", row.names=FALSE)


```


